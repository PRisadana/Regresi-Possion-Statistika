{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nama database dan collection\n",
    "db_name = 'regresiPossionYTRewind'\n",
    "collection_label = 'labelingData2018'\n",
    "collection_name = 'fullLabeledData2018'\n",
    "\n",
    "# Memuat value dari file .env\n",
    "load_dotenv()\n",
    "\n",
    "mongodb_url = os.getenv('URL_SANDY')\n",
    "local_url = os.getenv('URL_LOCAL')\n",
    "\n",
    "# Membuat koneksi ke MongoDB\n",
    "client = MongoClient(local_url)\n",
    "db = client[db_name]\n",
    "labeling_data = db[collection_label]\n",
    "full_labeled_data = db[collection_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mengambil data dari MongoDB ke dalam dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi label untuk data tidak berlabel telah selesai dan diupdate dalam koleksi MongoDB.\n"
     ]
    }
   ],
   "source": [
    "# Mengambil data dari koleksi MongoDB\n",
    "labeled_data = list(labeling_data.find())\n",
    "unlabeled_data = list(full_labeled_data.find())\n",
    "\n",
    "# Konversi data menjadi dataframe\n",
    "df_labeled = pd.DataFrame(labeled_data)\n",
    "df_unlabeled = pd.DataFrame(unlabeled_data)\n",
    "\n",
    "# Memisahkan fitur dan label dari data yang berlabel\n",
    "X_labeled = df_labeled['textOriginal']\n",
    "y_labeled = df_labeled['label']\n",
    "\n",
    "# Menggunakan TfidfVectorizer untuk mengubah teks menjadi fitur\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_labeled_tfidf = vectorizer.fit_transform(X_labeled)\n",
    "\n",
    "# Menggunakan SMOTE untuk melakukan oversampling pada data berlabel\n",
    "smote = SMOTE(random_state=42)\n",
    "X_labeled_tfidf_res, y_labeled_res = smote.fit_resample(X_labeled_tfidf, y_labeled)\n",
    "\n",
    "# Melatih model menggunakan data berlabel yang telah di-oversample\n",
    "model = MultinomialNB()\n",
    "model.fit(X_labeled_tfidf_res, y_labeled_res)\n",
    "\n",
    "# Memproses data yang tidak berlabel\n",
    "X_unlabeled = df_unlabeled['textOriginal']\n",
    "X_unlabeled_tfidf = vectorizer.transform(X_unlabeled)\n",
    "\n",
    "# Memprediksi label untuk data yang tidak berlabel\n",
    "y_unlabeled_pred = model.predict(X_unlabeled_tfidf)\n",
    "\n",
    "# Menambahkan prediksi ke dalam dataframe data tidak berlabel\n",
    "df_unlabeled['predicted_label'] = y_unlabeled_pred\n",
    "\n",
    "# Mengupdate koleksi MongoDB dengan prediksi label\n",
    "for index, row in df_unlabeled.iterrows():\n",
    "    full_labeled_data.update_one(\n",
    "        {\"_id\": row[\"_id\"]},\n",
    "        {\"$set\": {\"predicted_label\": row[\"predicted_label\"]}}\n",
    "    )\n",
    "\n",
    "print(f\"Prediksi label untuk data tidak berlabel telah selesai dan diupdate dalam koleksi MongoDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mengambil data dari koleksi MongoDB\n",
    "# labeled_data = list(labeling_data.find())\n",
    "# unlabeled_data = list(full_labeled_data.find())\n",
    "\n",
    "# # Konversi data menjadi dataframe\n",
    "# df_labeled = pd.DataFrame(labeled_data)\n",
    "# df_unlabeled = pd.DataFrame(unlabeled_data)\n",
    "\n",
    "# # Memisahkan fitur dan label dari data yang berlabel\n",
    "# X_labeled = df_labeled['textOriginal']\n",
    "# y_labeled = df_labeled['label']\n",
    "\n",
    "# # # Evaluasi model dengan membagi data berlabel menjadi train dan test set\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train Data\n",
    "# # Menggunakan TfidfVectorizer untuk mengubah teks menjadi fitur\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X_labeled_tfidf = vectorizer.fit_transform(X_labeled)\n",
    "\n",
    "# # Melatih model menggunakan Naive Bayes\n",
    "# model = MultinomialNB()\n",
    "# model.fit(X_labeled_tfidf, y_labeled)\n",
    "\n",
    "# # Memproses data yang tidak berlabel\n",
    "# X_unlabeled = df_unlabeled['textOriginal']\n",
    "# X_unlabeled_tfidf = vectorizer.transform(X_unlabeled)\n",
    "\n",
    "# # Memprediksi label untuk data yang tidak berlabel\n",
    "# y_unlabeled_pred = model.predict(X_unlabeled_tfidf)\n",
    "\n",
    "# # Menambahkan prediksi ke dalam dataframe data tidak berlabel\n",
    "# df_unlabeled['predicted_label'] = y_unlabeled_pred\n",
    "\n",
    "# # Mengupdate koleksi MongoDB dengan prediksi label\n",
    "# for index, row in df_unlabeled.iterrows():\n",
    "#     full_labeled_data.update_one(\n",
    "#         {\"_id\": row[\"_id\"]},\n",
    "#         {\"$set\": {\"predicted_label\": row[\"predicted_label\"]}}\n",
    "#     )\n",
    "\n",
    "# print(\"Prediksi label untuk data tidak berlabel telah selesai dan diupdate dalam koleksi MongoDB.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model: 0.625\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.44      0.69      0.54        81\n",
      "      netral       0.79      0.51      0.62       196\n",
      "     positif       0.64      0.77      0.70       123\n",
      "\n",
      "    accuracy                           0.62       400\n",
      "   macro avg       0.62      0.66      0.62       400\n",
      "weighted avg       0.67      0.62      0.63       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mengambil data dari koleksi MongoDB\n",
    "labeled_data = list(labeling_data.find())\n",
    "\n",
    "# Konversi data menjadi dataframe\n",
    "df_labeled = pd.DataFrame(labeled_data)\n",
    "\n",
    "# Memisahkan fitur dan label dari data yang berlabel\n",
    "X_labeled = df_labeled['textOriginal']\n",
    "y_labeled = df_labeled['label']\n",
    "\n",
    "# Evaluasi model dengan membagi data berlabel menjadi train dan test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Menggunakan TfidfVectorizer untuk mengubah teks menjadi fitur\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Menggunakan SMOTE untuk melakukan oversampling pada data latih\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_tfidf_res, y_train_res = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Melatih model menggunakan data train yang telah di-oversample\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf_res, y_train_res)\n",
    "\n",
    "# Memprediksi data test\n",
    "y_test_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Menghitung akurasi\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Akurasi model: {accuracy}\")\n",
    "\n",
    "# Mencetak classification report\n",
    "report = classification_report(y_test, y_test_pred)\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas: netral, Jumlah: 925\n",
      "Kelas: positif, Jumlah: 603\n",
      "Kelas: negatif, Jumlah: 472\n"
     ]
    }
   ],
   "source": [
    "# Nama database dan koleksi\n",
    "db_name = 'cobaAnalisisYTRewindIndonesia'\n",
    "collection_name = 'labelingData2018'\n",
    "\n",
    "# Membuat koneksi ke MongoDB\n",
    "client = MongoClient(local_url)\n",
    "db = client[db_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Query agregasi untuk menghitung jumlah setiap kelas berdasarkan predicted_label\n",
    "pipeline = [\n",
    "    {\"$group\": {\"_id\": \"$label\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$match\": {\"_id\": {\"$in\": [\"positif\", \"negatif\", \"netral\"]}}}\n",
    "]\n",
    "\n",
    "# Menjalankan query agregasi\n",
    "results = collection.aggregate(pipeline)\n",
    "\n",
    "# Menampilkan hasil\n",
    "for result in results:\n",
    "    print(f\"Kelas: {result['_id']}, Jumlah: {result['count']}\")\n",
    "\n",
    "# Menutup koneksi\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas: netral, Jumlah: 3491\n",
      "Kelas: negatif, Jumlah: 3208\n",
      "Kelas: positif, Jumlah: 3301\n"
     ]
    }
   ],
   "source": [
    "# Nama database dan koleksi\n",
    "db_name = 'cobaAnalisisYTRewindIndonesia'\n",
    "collection_name = 'fullLabeledData2018'\n",
    "\n",
    "# Membuat koneksi ke MongoDB\n",
    "client = MongoClient(local_url)\n",
    "db = client[db_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Query agregasi untuk menghitung jumlah setiap kelas berdasarkan predicted_label\n",
    "pipeline = [\n",
    "    {\"$group\": {\"_id\": \"$predicted_label\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$match\": {\"_id\": {\"$in\": [\"positif\", \"negatif\", \"netral\"]}}}\n",
    "]\n",
    "\n",
    "# Menjalankan query agregasi\n",
    "results = collection.aggregate(pipeline)\n",
    "\n",
    "# Menampilkan hasil\n",
    "for result in results:\n",
    "    print(f\"Kelas: {result['_id']}, Jumlah: {result['count']}\")\n",
    "\n",
    "# Menutup koneksi\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topik dalam komentar positif:\n",
      "Topik 1: keren, rewind, indonesia, bagus, youtube, lebih, banget, nya, mantap, the, god, sih, best, yt, job, ytr, buat, sama, lah, merinding\n",
      "\n",
      "Topik dalam komentar negatif:\n",
      "Topik 1: dislike, nya, ga, kurang, bowo, rewind, bagus, banyak, aja, kok, gk, sama, youtube, sih, youtuber, trending, semua, lebih, gua, yang\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Nama database dan collection\n",
    "db_name = 'cobaAnalisisYTRewindIndonesia'\n",
    "collection_name = 'fullLabeledData2018'\n",
    "\n",
    "# Memuat value dari file .env\n",
    "load_dotenv()\n",
    "\n",
    "local_url = os.getenv('URL_LOCAL')\n",
    "\n",
    "# Membuat koneksi ke MongoDB\n",
    "client = MongoClient(local_url)\n",
    "db = client[db_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Mengambil data dari koleksi MongoDB\n",
    "data = list(collection.find())\n",
    "\n",
    "# Konversi data menjadi dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Memisahkan komentar positif dan negatif\n",
    "df_positive = df[df['predicted_label'] == 'positif']\n",
    "df_negative = df[df['predicted_label'] == 'negatif']\n",
    "\n",
    "def lda_topic_modeling(texts, n_topics=5, n_words=5):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "    lda.fit(X)\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    topics = []\n",
    "    for idx, topic in enumerate(lda.components_):\n",
    "        topics.append([words[i] for i in topic.argsort()[:-n_words - 1:-1]])\n",
    "    return topics\n",
    "\n",
    "# Ekstraksi topik dari komentar positif\n",
    "positive_topics = lda_topic_modeling(df_positive['textOriginal'], n_topics=1, n_words=20)\n",
    "print(\"Topik dalam komentar positif:\")\n",
    "for i, topic in enumerate(positive_topics):\n",
    "    print(f\"Topik {i + 1}: {', '.join(topic)}\")\n",
    "\n",
    "# Ekstraksi topik dari komentar negatif\n",
    "negative_topics = lda_topic_modeling(df_negative['textOriginal'], n_topics=1, n_words=20)\n",
    "print(\"\\nTopik dalam komentar negatif:\")\n",
    "for i, topic in enumerate(negative_topics):\n",
    "    print(f\"Topik {i + 1}: {', '.join(topic)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluasi model dengan membagi data berlabel menjadi train dan test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Transformasi data train dan test menggunakan TF-IDF\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# # Melatih model menggunakan data train\n",
    "# model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Memprediksi data test\n",
    "# y_test_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# # Menghitung akurasi\n",
    "# accuracy = accuracy_score(y_test, y_test_pred)\n",
    "# print(f\"Akurasi model: {accuracy}\")\n",
    "\n",
    "# # Mencetak classification report\n",
    "# report = classification_report(y_test, y_test_pred)\n",
    "# print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Jika data tidak berlabel memiliki label asli untuk keperluan evaluasi\n",
    "# if 'label' in df_unlabeled.columns:\n",
    "#     print(\"\\nEvaluasi kinerja model:\")\n",
    "#     print(\"Accuracy Score:\", accuracy_score(df_unlabeled['label'], df_unlabeled['predicted_label']))\n",
    "#     print(\"Classification Report:\\n\", classification_report(df_unlabeled['label'], df_unlabeled['predicted_label']))\n",
    "# else:\n",
    "#     print(\"Data tidak berlabel tidak memiliki label asli untuk evaluasi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
